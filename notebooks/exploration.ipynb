{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1af94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:47:46.901358: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-27 15:47:46.972515: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-27 15:47:48.712270: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-27 15:47:48.712270: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd2b2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# notebook is at music_classifier/notebooks; add the sibling scripts/ dir\n",
    "sys.path.insert(0, str((Path.cwd() / '..' / 'scripts').resolve()))\n",
    "\n",
    "# Now import as if preprocess.py were in the notebook folder\n",
    "from preprocess import load_dataset\n",
    "from transforms import apply_random_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db2b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:47:53.542242: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model. input shape: (None, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "model_path = '/media/suraj/SSD/programming/Thesis/aigm-classifier/models/audio_classifier_model.keras'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print('Loaded model. input shape:', model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01de71d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Conv2D name=conv2d, built=True>,\n",
       " <MaxPooling2D name=max_pooling2d, built=True>,\n",
       " <Conv2D name=conv2d_1, built=True>,\n",
       " <MaxPooling2D name=max_pooling2d_1, built=True>,\n",
       " <Conv2D name=conv2d_2, built=True>,\n",
       " <MaxPooling2D name=max_pooling2d_2, built=True>,\n",
       " <Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dropout name=dropout, built=True>,\n",
       " <Dense name=dense_1, built=True>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e24682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 audio files\n",
      "Saved 0 results to results/metrics/transform_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# Discover audio files under data/testset/real/\n",
    "audio_patterns = ['**/*.wav','**/*.mp3','**/*.flac','**/*.ogg']\n",
    "data_root = Path('data/testset/real')\n",
    "files = []\n",
    "for pat in audio_patterns:\n",
    "    files += list(data_root.glob(pat))\n",
    "files = [p for p in files if p.is_file()]\n",
    "print(f'Found {len(files)} audio files')\n",
    "\n",
    "def prepare_input(y, sr, model):\n",
    "    # Determine target mel bins and time frames from model input if possible\n",
    "    input_shape = model.input_shape\n",
    "    if len(input_shape) == 4:\n",
    "        _, freq, time, ch = input_shape\n",
    "    elif len(input_shape) == 3:\n",
    "        _, freq, time = input_shape\n",
    "        ch = None\n",
    "    else:\n",
    "        raise RuntimeError(f'Unexpected model.input_shape: {input_shape}')\n",
    "    freq = freq or 128\n",
    "    # Recompute mel spectrogram with matching n_mels\n",
    "    mel = compute_mel(y, n_mels=freq)\n",
    "    # Pad/truncate time axis to 'time' if provided\n",
    "    if time is not None and mel.shape[1] != time:\n",
    "        if mel.shape[1] < time:\n",
    "            pad_width = time - mel.shape[1]\n",
    "            mel = np.pad(mel, ((0,0),(0,pad_width)), mode='constant', constant_values=mel.min())\n",
    "        else:\n",
    "            mel = mel[:, :time]\n",
    "    X = mel.astype('float32')\n",
    "    if ch is not None:\n",
    "        X = X[:, :, np.newaxis]\n",
    "    return X\n",
    "\n",
    "def evaluate_file(path, model):\n",
    "    y, sr = load_audio(str(path), sr=22050)\n",
    "    # If stereo, prefer mono for model input unless model expects 2 channels\n",
    "    try:\n",
    "        y_t = apply_random_transforms(y, sr)\n",
    "    except Exception as e:\n",
    "        print('Transform failed, using original audio:', e)\n",
    "        y_t = y\n",
    "    X = prepare_input(y_t, sr, model)\n",
    "    pred = model.predict(np.expand_dims(X, 0))\n",
    "    return pred, X.shape\n",
    "\n",
    "# Sample and run transforms+inference\n",
    "n = min(10, len(files)) if len(files) > 0 else 0\n",
    "sample_files = random.sample(files, n) if n>0 else []\n",
    "results = []\n",
    "for p in sample_files:\n",
    "    try:\n",
    "        pred, shape = evaluate_file(p, model)\n",
    "        results.append((str(p), pred.tolist(), shape))\n",
    "        print(p, '->', pred, 'input shape', shape)\n",
    "    except Exception as e:\n",
    "        print('Error processing', p, e)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "out = Path('results/metrics')\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "with open(out / 'transform_evaluation.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print('Saved', len(results), 'results to', out / 'transform_evaluation.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
